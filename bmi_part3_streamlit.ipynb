{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1c233f07-f0a2-4523-b53b-bd2e36160e82",
      "metadata": {
        "id": "1c233f07-f0a2-4523-b53b-bd2e36160e82"
      },
      "source": [
        "# Face-to-BMI\n",
        "***\n",
        "## Machine Learning II\n",
        "\n",
        "By Amulya Jayanti | Halleluya Mengesha | Hira Stanley | Sami Naeem | Vaishnavi Kokadwar\n",
        "  \n",
        "*May, 2025*\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c8cb345",
      "metadata": {},
      "source": [
        "# PART 3: Web Application"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0cea062",
      "metadata": {},
      "source": [
        "**Note:** \n",
        "\n",
        "**Follow this link:** https://bmi-predictor-app-v2.streamlit.app/ (Please note we ran out of our quota and this stopped working, however we will demonstrate the app hosted locally)\n",
        "\n",
        "- Below is the code ran in our \"bmi_app_v2.py\" file - included here for reference.\n",
        "\n",
        "- To launch Streamlit app from terminal refer to below code:\n",
        "    - `cd \"/Users/halleluyamengesha/Desktop/UChicago/_Quarter_3/Machine Learning II/Project\"`\n",
        "    - `streamlit run bmi_app_v3.py` To start Streamlit app\n",
        "    - `Ctrl + C` - To end streamlit app"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cfba888",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run this\n",
        "# %pip install streamlit-webrtc opencv-python-headless"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d972e3db",
      "metadata": {},
      "outputs": [],
      "source": [
        "# import os\n",
        "# import streamlit as st\n",
        "# import numpy as np\n",
        "# import tensorflow as tf\n",
        "# import joblib\n",
        "# from PIL import Image\n",
        "# from tensorflow.keras.preprocessing.image import img_to_array\n",
        "# from tensorflow.keras.applications.vgg19 import preprocess_input as vgg_preprocess\n",
        "# from tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess\n",
        "# from streamlit_webrtc import webrtc_streamer, VideoTransformerBase\n",
        "\n",
        "# # 1) Load TFLite feature extractor based on model type\n",
        "# @st.cache_resource\n",
        "# def load_feature_model(model_type: str):\n",
        "#     if model_type == \"VGG19\":\n",
        "#         model_path = \"feature_extractors/vgg19_feature_extractor.tflite\"\n",
        "#     elif model_type == \"EfficientNet\":\n",
        "#         model_path = \"feature_extractors/efficientnet_feature_extractor.tflite\"\n",
        "#     else:\n",
        "#         raise ValueError(f\"Unknown model type: {model_type}\")\n",
        "#     interpreter = tf.lite.Interpreter(model_path=model_path)\n",
        "#     interpreter.allocate_tensors()\n",
        "#     return interpreter, interpreter.get_input_details(), interpreter.get_output_details()\n",
        "\n",
        "# # 2) Load scikit-learn regressors\n",
        "# @st.cache_resource\n",
        "# def load_regressors():\n",
        "#     specs = {\n",
        "#         \"VGG19-MLP\":       \"regressors/vgg19_ensemble_model.pkl\",\n",
        "#         \"EfficientNet-B3\": \"regressors/Ridge_regressor.pkl\"\n",
        "#     }\n",
        "#     loaded = {}\n",
        "#     for name, path in specs.items():\n",
        "#         if not os.path.exists(path):\n",
        "#             raise FileNotFoundError(f\"Regressor not found: {path}\")\n",
        "#         loaded[name] = joblib.load(path)\n",
        "#     return loaded\n",
        "\n",
        "# # 3) Image preprocessing helper (handles each model's input size)\n",
        "# def preprocess_image(img: Image.Image, model_type: str):\n",
        "#     if model_type == \"VGG19\":\n",
        "#         size, preprocess_fn = (224, 224), vgg_preprocess\n",
        "#     else:\n",
        "#         size, preprocess_fn = (300, 300), eff_preprocess\n",
        "#     img = img.resize(size).convert(\"RGB\")\n",
        "#     arr = img_to_array(img)[None, ...]\n",
        "#     return preprocess_fn(arr).astype(np.float32)\n",
        "\n",
        "# # 4) BMI prediction helper (single-frame)\n",
        "# def predict_bmi(img: Image.Image,\n",
        "#                 interpreter, in_det, out_det,\n",
        "#                 regressor, gender_vector,\n",
        "#                 model_type: str):\n",
        "#     data = preprocess_image(img, model_type)\n",
        "#     interpreter.set_tensor(in_det[0][\"index\"], data)\n",
        "#     interpreter.invoke()\n",
        "#     feats = interpreter.get_tensor(out_det[0][\"index\"])  # shape (1, N)\n",
        "#     expected = getattr(regressor, \"n_features_in_\", None)\n",
        "#     actual = feats.shape[1]\n",
        "#     if expected is not None:\n",
        "#         if actual + gender_vector.shape[1] == expected:\n",
        "#             feats = np.hstack([feats, gender_vector])\n",
        "#         elif actual != expected:\n",
        "#             raise ValueError(f\"Regressor expects {expected} features but got {actual}\")\n",
        "#     return float(regressor.predict(feats)[0])\n",
        "\n",
        "# # 5) Prediction from webcam frame\n",
        "# def predict_bmi_from_frame(frame, *args):\n",
        "#     img = Image.fromarray(frame)\n",
        "#     return predict_bmi(img, *args)\n",
        "\n",
        "# # 6) VideoTransformer for live inference\n",
        "# class LiveBMI(VideoTransformerBase):\n",
        "#     def __init__(self, model_type, regressor, gender_vector):\n",
        "#         self.interpreter, self.in_det, self.out_det = load_feature_model(model_type)\n",
        "#         self.regressor = regressor\n",
        "#         self.gender_vector = gender_vector\n",
        "#         self.model_type = model_type\n",
        "\n",
        "#     def transform(self, frame):\n",
        "#         import cv2\n",
        "#         img = frame.to_ndarray(format=\"bgr24\")\n",
        "#         try:\n",
        "#             bmi = predict_bmi_from_frame(\n",
        "#                 img,\n",
        "#                 self.interpreter, self.in_det, self.out_det,\n",
        "#                 self.regressor, self.gender_vector,\n",
        "#                 self.model_type\n",
        "#             )\n",
        "#             cv2.putText(img, f\"BMI: {bmi:.1f}\", (10, 30),\n",
        "#                         cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "#         except Exception:\n",
        "#             pass\n",
        "#         return img\n",
        "\n",
        "# # 7) BMI category helper\n",
        "# def get_bmi_category(bmi: float) -> str:\n",
        "#     if bmi < 18.5:\n",
        "#         return \"Underweight\"\n",
        "#     elif bmi < 25:\n",
        "#         return \"Normal weight\"\n",
        "#     elif bmi < 30:\n",
        "#         return \"Overweight\"\n",
        "#     else:\n",
        "#         return \"Obese\"\n",
        "\n",
        "# # 8) Streamlit App UI\n",
        "# st.set_page_config(page_title=\"BMI Predictor\", layout=\"centered\")\n",
        "# st.title(\"🤳 Predict Your BMI!\")\n",
        "\n",
        "# # Gender selection and pipeline choice\n",
        "# gender = st.selectbox(\"Select your gender:\", [\"Male\", \"Female\"])\n",
        "# if gender == \"Male\":\n",
        "#     model_type    = \"VGG19\"\n",
        "#     model_key     = \"VGG19-MLP\"\n",
        "#     gender_vector = np.array([[1]], dtype=np.float32)\n",
        "# else:\n",
        "#     model_type    = \"EfficientNet\"\n",
        "#     model_key     = \"EfficientNet-B3\"\n",
        "#     gender_vector = np.array([[0]], dtype=np.float32)\n",
        "\n",
        "# # Load models\n",
        "# regressors = load_regressors()\n",
        "# regressor  = regressors[model_key]\n",
        "# interpreter, in_det, out_det = load_feature_model(model_type)\n",
        "\n",
        "# # Show active pipeline\n",
        "# st.markdown(\n",
        "#     f\"**Active pipeline:**  \\n\"\n",
        "#     f\"- Feature extractor: `{model_type}`  \\n\"\n",
        "#     f\"- Regressor model:   `{model_key}`\"\n",
        "# )\n",
        "\n",
        "# # Input mode selector — note labels match the branches below\n",
        "# mode = st.radio(\n",
        "#     \"How would you like to provide your image?\",\n",
        "#     [\"Upload a photo\", \"Take a photo\", \"Live webcam\"]\n",
        "# )\n",
        "\n",
        "# # Live-webcam branch\n",
        "# if mode == \"Live webcam\":\n",
        "#     st.write(\"▶️ Starting live webcam…\")\n",
        "#     webrtc_streamer(\n",
        "#         key=\"live-bmi\",\n",
        "#         video_transformer_factory=lambda: LiveBMI(model_type, regressor, gender_vector),\n",
        "#         media_stream_constraints={\"video\": True, \"audio\": False},\n",
        "#         rtc_configuration={\"iceServers\":[{\"urls\":[\"stun:stun.l.google.com:19302\"]}]}\n",
        "#     )\n",
        "#     st.stop()\n",
        "\n",
        "# # Upload-photo branch\n",
        "# img = None\n",
        "# if mode == \"Upload a photo\":\n",
        "#     f = st.file_uploader(\"Upload an image (JPG/PNG/BMP)\", type=[\"jpg\",\"jpeg\",\"png\",\"bmp\"])\n",
        "#     if f:\n",
        "#         img = Image.open(f)\n",
        "\n",
        "# # Take-photo branch\n",
        "# elif mode == \"Take a photo\":\n",
        "#     snap = st.camera_input(\"Take a photo with your camera\")\n",
        "#     if snap:\n",
        "#         img = Image.open(snap)\n",
        "\n",
        "# # Prediction UI\n",
        "# if img is not None:\n",
        "#     st.image(img, caption=\"Your input\", use_column_width=True)\n",
        "#     if st.button(\"🔍 Predict BMI\"):\n",
        "#         bmi = predict_bmi(\n",
        "#             img,\n",
        "#             interpreter, in_det, out_det,\n",
        "#             regressor, gender_vector,\n",
        "#             model_type\n",
        "#         )\n",
        "#         category = get_bmi_category(bmi)\n",
        "#         st.success(f\"📏 Predicted BMI: {bmi:.1f}\")\n",
        "#         st.info(f\"Category: {category}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
